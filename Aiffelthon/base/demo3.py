# ê°œì„ (ì‹¤í—˜ì¤‘)ëœ context. ë°ì´í„°ê°€ ì—†ì–´ì„œ ì ì‹œ ì¤‘ë‹¨.

import os
import warnings
import json
from ai.demo import DG_LIST, generate_stream_response
warnings.filterwarnings('ignore')

import streamlit as st

st.set_page_config(
    page_title="IMDGGenie.ai",
    page_icon="ğŸ¤–",
    layout="centered"
)

WORKFLOW_STEPS = {
    "1": "ì œí’ˆ ì…ê³ ",
    "2": "MSDS í™•ì¸",
    "3": "ìœ„í—˜ë¬¼ í¬ì¥",
    "4": "ì„ ì  ì„œë¥˜ ì‘ì„±, ìŠ¹ì¸ ìš”ì²­",
    "5": "ìœ„í—˜ë¬¼ ê²€ì‚¬ ì‹ ì²­",
    "6": "ì»¨í…Œì´ë„ˆ ë°°ì°¨",
    "7": "ì»¨í…Œì´ë„ˆ ì¥ì…",
    "8": "ê²€ì‚¬ì¦ ì¡°íšŒ",
    "9": "ìˆ˜ì¶œ ì§„í–‰"
}

os.environ["USER_AGENT"] = "IMDGGenie.ai"

from dotenv import load_dotenv
load_dotenv()

from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain_openai import ChatOpenAI
from langchain_community.document_loaders import PyPDFLoader
from langchain.prompts import ChatPromptTemplate
from langchain.schema.output_parser import StrOutputParser
from langchain.schema.runnable import RunnablePassthrough
from langchain.text_splitter import RecursiveCharacterTextSplitter
from fuzzywuzzy import process
import random
import re

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (íŒŒì¼ ìƒë‹¨, st.set_page_config ì•„ë˜ì— ì¶”ê°€)
if 'full_response' not in st.session_state:
    st.session_state.full_response = ""

if 'user_input' not in st.session_state:
    st.session_state.user_input = ""

def create_vector_db():
    """Vector DB ìƒì„± í•¨ìˆ˜"""
    vector_store_path = "./resources/vector/index"
    pdf_path = "./resources/docs/IMDG_ê²©ë¦¬ê·œì •ì•ˆë‚´ì„œ.pdf"
    
    try:
        if os.path.exists(vector_store_path):
            print("Vector DB already exists. Skipping creation.")
            embeddings = OpenAIEmbeddings()
            FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)
            return
    except Exception as e:
        print(f"Error loading existing vector DB: {e}")
        print("Creating new Vector DB...")
        
        try:
            loader = PyPDFLoader(pdf_path)
            documents = loader.load()

            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=1000,
                chunk_overlap=200
            )
            splits = text_splitter.split_documents(documents)

            embeddings = OpenAIEmbeddings()
            vectorstore = FAISS.from_documents(splits, embeddings)
            
            os.makedirs(os.path.dirname(vector_store_path), exist_ok=True)
            vectorstore.save_local(vector_store_path)
            print("Vector DB created successfully.")
        except Exception as e:
            print(f"Error creating vector DB: {e}")
            raise

def load_faiss_vector():
    """FAISS ë²¡í„° ë¡œë“œ í•¨ìˆ˜"""
    vector_store_path = "./resources/vector/index"
    try:
        embeddings = OpenAIEmbeddings()
        vectorstore = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)
        return vectorstore.as_retriever(search_kwargs={"k": 2})
    except Exception as e:
        print(f"Error loading FAISS vector: {e}")
        raise

def load_dangerous_goods_from_json():
    """IMDG ìœ„í—˜ë¬¼ ëª©ë¡ JSON íŒŒì¼ ë¡œë“œ"""
    file_path = '/Users/minhyeok/Desktop/PROJECT/Aiffelthon/aiffelthon_tys_imdg/tys/baseline/app/resources/docs/imdg_ìœ„í—˜ë¬¼ëª©ë¡.json'
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            return data.get("dangerousGoodsList", [])
    except Exception as e:
        print(f"Error loading IMDG dangerous goods list: {e}")
        return []

def search_dangerous_goods(dg_json_list, query_terms, response_text=None, user_input=None):
    """ìœ„í—˜ë¬¼ ëª©ë¡ì—ì„œ ê²€ìƒ‰ì–´ì™€ ê´€ë ¨ëœ í•­ëª© ì°¾ê¸° - UN ë²ˆí˜¸ ìš°ì„  ë§¤ì¹­ ê°œì„  ë²„ì „"""
    if not dg_json_list:
        return []
    
    found_items = []
    
    def extract_un_numbers(text):
        if not text:
            return set()
        patterns = [
            r'UN\s*(\d{4})',      # UN 1234
            r'UN(\d{4})',         # UN1234
            r'ìœ ì—”\s*(\d{4})',     # ìœ ì—” 1234
            r'ìœ ì—”ë²ˆí˜¸\s*(\d{4})',  # ìœ ì—”ë²ˆí˜¸ 1234
            r'UN No\s*:\s*(\d{4})',# UN No: 1234
            r'UN Number\s*:\s*(\d{4})'  # UN Number: 1234
        ]
        numbers = set()
        for pattern in patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            numbers.update(matches)
        return numbers

    # 1ë‹¨ê³„: UN ë²ˆí˜¸ ì§ì ‘ ë§¤ì¹­
    un_numbers = set()
    # ì§ˆë¬¸ì—ì„œ UN ë²ˆí˜¸ ì¶”ì¶œ
    if user_input:
        un_numbers.update(extract_un_numbers(user_input))
    # ë‹µë³€ì—ì„œ UN ë²ˆí˜¸ ì¶”ì¶œ
    if response_text:
        un_numbers.update(extract_un_numbers(response_text))
    
    # UN ë²ˆí˜¸ë¡œ ì§ì ‘ ë§¤ì¹­ë˜ëŠ” í•­ëª© ë¨¼ì € ì°¾ê¸°
    if un_numbers:
        for un_number in un_numbers:
            for item in dg_json_list:
                if item.get('unNumber', '') == un_number:
                    found_items.append(item)
                    break  # í•´ë‹¹ UN ë²ˆí˜¸ í•­ëª©ì„ ì°¾ìœ¼ë©´ ì¤‘ë‹¨
    
    # 2ë‹¨ê³„: í‚¤ì›Œë“œ ê¸°ë°˜ ì¹´í…Œê³ ë¦¬ ë§¤ì¹­
    if len(found_items) < 5:  # UN ë²ˆí˜¸ ë§¤ì¹­ í›„ ë‚¨ì€ ê³µê°„ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ
        categories = {}
        for item in dg_json_list:
            if item in found_items:  # ì´ë¯¸ ì°¾ì€ í•­ëª©ì€ ê±´ë„ˆë›°ê¸°
                continue
                
            score = 0
            psn_ko = item.get('properShippingName', {}).get('ko', '').lower()
            psn_en = item.get('properShippingName', {}).get('en', '').lower()
            
            # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
            for term in query_terms:
                term = term.lower()
                if term in psn_ko or term in psn_en:
                    score += 10
                if response_text and term in response_text.lower():
                    score += 5

            if score >= 10:
                category_name = None
                for key in ["íƒ„", "ê°€ìŠ¤", "ì‚°", "ì—¼"]:
                    if key in psn_ko:
                        category_name = psn_ko.split(key)[0] + key
                        break
                
                if category_name:
                    if category_name not in categories:
                        categories[category_name] = []
                    categories[category_name].append((item, score))
        
        # ì¹´í…Œê³ ë¦¬ë³„ ëŒ€í‘œ í•­ëª© ì¶”ê°€
        for category, items in categories.items():
            if len(found_items) >= 5:
                break
            items.sort(key=lambda x: x[1], reverse=True)
            if items[0][0] not in found_items:
                found_items.append(items[0][0])
    
    return found_items

def generate_dynamic_follow_up_questions(user_input, context):
    """AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë™ì ìœ¼ë¡œ í›„ì† ì§ˆë¬¸ ìƒì„±"""
    prompt = f"""
    Given the context and the user input, generate three follow-up questions that are relevant to the topic.

    Context:
    {context}

    User Input:
    {user_input}

    Follow-up Questions:
    1.
    2.
    3.
    """
    model = ChatOpenAI(model="gpt-4o-mini", temperature=0.5)
    response = model(prompt)
    
    follow_up_questions = response.split("\n")
    return [q.strip() for q in follow_up_questions if q.strip()]

# Create sidebar menu
menu = st.sidebar.selectbox("Menu", ["Context", "Segregator"])

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'asked_questions' not in st.session_state:
    st.session_state.asked_questions = set()

if menu == "Context":
    st.title("IMDGGenie.ai Context Chatbot")

    try:
        create_vector_db()
        retriever = load_faiss_vector()
        
        dangerous_goods_json = load_dangerous_goods_from_json()

        if not dangerous_goods_json:
            st.error("ìœ„í—˜ë¬¼ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            st.stop()

        if 'user_input' not in st.session_state:
            st.session_state.user_input = ""

        user_input = st.text_input("Enter your question about IMDG Code:", st.session_state.user_input)

        if user_input:
            keywords = [word.strip() for word in user_input.split() if len(word.strip()) > 1]
            
            # ê°œì„ ëœ ì§ˆë¬¸ ìƒì„±
            refine_template = """
            You are an IMDG Code expert. Please improve the given question to be more specific and professional.
            Make it more detailed while maintaining the original intent.

            Original Question:
            {question}

            Instructions:
            1. Enhance the question to be more specific and technical
            2. Include relevant IMDG Code terminology
            3. Focus on safety and regulatory aspects
            4. Keep the improved question in Korean
            5. Maintain the core meaning of the original question

            Improved Question:
            """

            refine_prompt = ChatPromptTemplate.from_template(refine_template)
            refine_model = ChatOpenAI(model="gpt-4o-mini", temperature=0.2)
            refine_chain = refine_prompt | refine_model | StrOutputParser()

            # ê°œì„ ëœ ì§ˆë¬¸ ìƒì„±
            refined_question = refine_chain.invoke({"question": user_input})

            # ë©”ì¸ ë‹µë³€ì„ ìœ„í•œ chain ì •ì˜
            template = """
            You are a senior IMDG Code expert with extensive experience. Please provide a detailed and structured answer to the question.

            Context:
            {context}

            Dangerous Goods List:
            {dangerous_goods_list}

            Question: 
            {question}

            Instructions:
            1. Answer in Korean with a professional and detailed manner
            2. Structure your response with clear sections using markdown
            3. Include the following elements in your answer:
               - Main explanation with relevant IMDG Code references
               - Specific requirements and procedures
               - Safety considerations and precautions
               - Practical implementation guidelines
               - Related regulations and standards

            Format your response as:

            ### ğŸ“Œ ë‹µë³€
            [Detailed main answer with structured sections]

            ### ğŸ” ì„¸ë¶€ ìš”êµ¬ì‚¬í•­
            - [Specific requirements]
            - [Detailed procedures]
            - [Safety measures]

            ### âš ï¸ ì£¼ì˜ì‚¬í•­
            - [Important precautions]
            - [Critical considerations]

            ### ğŸ“‹ ì°¸ê³ ì‚¬í•­
            - [Additional relevant information]
            - [IMDG Code references]

            ### í›„ì† ì§ˆë¬¸:
            1. [Specific follow-up question about detailed requirements]
            2. [Follow-up question about practical implementation]
            3. [Follow-up question about safety considerations]
            """

            prompt = ChatPromptTemplate.from_template(template)
            model = ChatOpenAI(model="gpt-4o-mini", temperature=0.2)
            
            chain = (
                {
                    "context": retriever,
                    "question": RunnablePassthrough(),
                    "dangerous_goods_list": lambda _: json.dumps(found_dangerous_goods, ensure_ascii=False)[:1000] if found_dangerous_goods else "No matching dangerous goods found"
                }
                | prompt
                | model
                | StrOutputParser()
            )

            # ê°œì„ ëœ ì§ˆë¬¸ í‘œì‹œ
            st.write("---")
            st.write(f"**ì›ë˜ ì§ˆë¬¸**: {user_input}")
            st.write(f"**ê°œì„  ì§ˆë¬¸**: {refined_question}")
            st.write("---")

            # ìœ„í—˜ë¬¼ ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±
            found_dangerous_goods = search_dangerous_goods(
                dangerous_goods_json, 
                keywords + refined_question.split(), 
                st.session_state.full_response,
                user_input
            )

            # ë©”ì¸ ë‹µë³€ í‘œì‹œ
            response_container = st.empty()
            st.session_state.full_response = ""
            
            # Generate streaming response
            for chunk in chain.stream(refined_question):
                st.session_state.full_response += chunk
                response_container.markdown(st.session_state.full_response)
            
            try:
                # ë‹µë³€ì—ì„œ í›„ì† ì§ˆë¬¸ ì¶”ì¶œ
                response_text = st.session_state.full_response
                if "### í›„ì† ì§ˆë¬¸:" in response_text:
                    questions_section = response_text.split("### í›„ì† ì§ˆë¬¸:")[1].strip()
                    follow_up_questions = []
                    
                    # ë²ˆí˜¸ê°€ ë§¤ê²¨ì§„ ì§ˆë¬¸ë“¤ì„ ì¶”ì¶œ
                    for line in questions_section.split("\n"):
                        if line.strip().startswith(("1.", "2.", "3.")):
                            question = line.strip().split(". ", 1)[1]
                            if question:  # ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì¶”ê°€
                                follow_up_questions.append(question)
                    
                    if follow_up_questions:
                        st.write("---")
                        
                        # 3ê°œì˜ ì»¬ëŸ¼ ìƒì„±
                        cols = st.columns(3)
                        
                        # ê° ì»¬ëŸ¼ì— ë²„íŠ¼ ë°°ì¹˜
                        for idx, (col, question) in enumerate(zip(cols, follow_up_questions)):
                            with col:
                                if st.button(f"ğŸ‘‰ \n{question}", key=f"btn_{idx}", use_container_width=True):
                                    st.session_state.user_input = question
                                    st.experimental_rerun()
            
            except Exception as e:
                print(f"Error processing recommended questions: {e}")

            # ìœ„í—˜ë¬¼ ì •ë³´ í‘œì‹œ
            if found_dangerous_goods:
                st.write("---")
                st.write("### ğŸ“¦ ê´€ë ¨ ìœ„í—˜ë¬¼ ì •ë³´")
                for item in found_dangerous_goods:
                    with st.expander(f"ğŸ” {item['properShippingName']['ko']} (UN {item['unNumber']})"):
                        st.markdown(f"""
                        ### â¦¿ ìœ„í—˜ë¬¼ ì •ë³´:
                        - **UN ë²ˆí˜¸**: {item.get('unNumber', 'ì •ë³´ ì—†ìŒ')}
                        - **ìœ„í—˜ë¬¼ ë¶„ë¥˜**: {item.get('class', 'ì •ë³´ ì—†ìŒ')}
                        - **ë¶€ìœ„í—˜ì„±**: {item.get('subsidiaryRisk', 'ì •ë³´ ì—†ìŒ')}
                        - **ìš©ê¸°ë“±ê¸‰**: {item.get('packingGroup', 'ì •ë³´ ì—†ìŒ')}
                        
                        #### í’ˆëª©ëª…
                        - ğŸ‡°ğŸ‡· {item['properShippingName'].get('ko', 'ì •ë³´ ì—†ìŒ')}
                        - ğŸ‡ºğŸ‡¸ {item['properShippingName'].get('en', 'ì •ë³´ ì—†ìŒ')}
                        
                        #### íŠ¹ë³„ ê·œì •
                        {item.get('specialProvisions', 'íŠ¹ë³„ ê·œì • ì—†ìŒ')}
                        
                        #### í¬ì¥ ê·œì •
                        - **í¬ì¥ ì§€ì¹¨**: {item.get('packing', {}).get('instruction', 'ì •ë³´ ì—†ìŒ')}
                        - **íŠ¹ë³„ í¬ì¥ ê·œì •**: {item.get('packing', {}).get('provisions', 'ì •ë³´ ì—†ìŒ')}
                        """)

    except Exception as e:
        st.error(f"An error occurred: {str(e)}")

if menu == "Segregator":
    st.title("IMDGGenie.ai Segregator")

    # Select deck position
    deck_position = st.selectbox("Deck Position", ["Below Deck", "Above Deck"])

    # List of dangerous goods
    dg_items = DG_LIST.get_all_un_no()
    dg_options = [(f"{item['unNumber']} - {item['psn']}", item["unNumber"]) for item in dg_items]
    dg_labels = [label for label, _ in dg_options]

    left, right = st.columns(2) 
    with left:
        st.subheader("Container 1")
        cntr_type_1 = st.selectbox(label="Container Type", options=["Closed", "Open"], key="cntr_type_1")
        selected_label_1 = st.selectbox("UN Number", options=dg_labels, index=None, placeholder="Select UN number", key="un_number_1")
        if selected_label_1:
            un_number_1 = next(value for label, value in dg_options if selected_label_1 == label)
            oid_1 = next(item for item in dg_items if item["unNumber"] == un_number_1)["id"]
            item_1 = DG_LIST.find_one(oid_1)

            st.write("#### Dangerous Goods Information")
            st.write(f"**UN Number:** {item_1['unNumber']}")
            st.write(f"**Class:** {item_1['class']}")
            st.write(f"**Subsidiary Risk:** {item_1.get('subsidiaryRisk', '-')}")
            st.write(f"**Packing Group:** {item_1.get('packingGroup', '-')}")
            st.write(f"**Proper Shipping Name (PSN):** {item_1['properShippingName']['ko']}")
    with right:
        st.subheader("Container 2")
        cntr_type_2 = st.selectbox(label="Container Type", options=["Closed", "Open"], key="cntr_type_2")
        selected_label_2 = st.selectbox("UN Number", options=dg_labels, index=None, placeholder="Select UN number", key="un_number_2")
        if selected_label_2:
            un_number_2 = next(value for label, value in dg_options if selected_label_2 == label)
            oid_2 = next(item for item in dg_items if item["unNumber"] == un_number_2)["id"]
            item_2 = DG_LIST.find_one(oid_2)

            st.write("#### Dangerous Goods Information")
            st.write(f"**UN Number:** {item_2['unNumber']}")
            st.write(f"**Class:** {item_2['class']}")
            st.write(f"**Subsidiary Risk:** {item_2.get('subsidiaryRisk', '-')}")
            st.write(f"**Packing Group:** {item_2.get('packingGroup', '-')}")
            st.write(f"**Proper Shipping Name (PSN):** {item_2['properShippingName']['ko']}")

    st.divider()

    if st.button("Analyze Segregation Requirements"):
        input = {
            "containers": [
                {
                    "un_number": un_number_1,
                    "cntr_type": cntr_type_1
                },
                {
                    "un_number": un_number_2,
                    "cntr_type": cntr_type_2
                }
            ],
            "deck_position": deck_position
        }
        response_stream = generate_stream_response(input)

        container = st.container(border=True)
        result = ""
        with container.empty():
            for data in response_stream:
                dict = json.loads(data)
                status = dict["status"]
                chunk = dict["data"]
                if status == "processing":
                    st.markdown(chunk)
                elif status == "streaming":
                    result += chunk
                    st.markdown(result)


